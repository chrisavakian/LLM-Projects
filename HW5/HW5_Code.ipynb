{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badc9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as si\n",
    "import scipy.io as sio\n",
    "from math import log2\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_csv(y_test):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1  # Ensures that the index starts at 1\n",
    "    df.to_csv('submission.csv', index_label='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    class Node:\n",
    "        def __init__(self, feature = None, threshold = None, left = None, right = None, value = None):\n",
    "            self.feature = feature\n",
    "            self.threshold = threshold\n",
    "            self.left = left\n",
    "            self.right = right\n",
    "            self.val = value\n",
    "        \n",
    "        def is_leaf(self):\n",
    "            return self.val is not None\n",
    "\n",
    "    def __init__(self, depth):\n",
    "        self.depth = depth\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.grow(X, y, 0)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        collect = [self.traverse(i, self.tree) for i in X]\n",
    "        return np.array(collect)\n",
    "\n",
    "    def common_label(self, y):\n",
    "        counter = Counter(y)\n",
    "        most_common = counter.most_common(1)[0][0]\n",
    "        return most_common\n",
    "\n",
    "    def entropy(self, y):\n",
    "        num_of_ys = Counter(y)\n",
    "        v = 0\n",
    "        for i in num_of_ys:\n",
    "            p = num_of_ys[i] / len(y)\n",
    "            v -= p * log2(p)\n",
    "        return v\n",
    "\n",
    "    def grow(self, X, y, depth):\n",
    "        rows, columns = X.shape\n",
    "        num_labels = len(set(y))\n",
    "\n",
    "        randcolumns = np.random.choice(columns, columns, replace=False)\n",
    "        optimal_feature, optimal_feature_threshold = self.optimal_split(X, y, randcolumns)\n",
    "\n",
    "        if depth >= self.depth or num_labels == 1:\n",
    "            commonlabel = self.common_label(y)\n",
    "            return self.Node(value=commonlabel)\n",
    "        \n",
    "        if optimal_feature is None:\n",
    "            commonlabel = self.common_label(y)\n",
    "            return self.Node(value = commonlabel)\n",
    "        else:\n",
    "            left_index, right_index = self.split(X[:, optimal_feature], optimal_feature_threshold)\n",
    "            left = self.grow(X[left_index, :], y[left_index], depth + 1)\n",
    "            right = self.grow(X[right_index, :], y[right_index], depth + 1)\n",
    "            return self.Node(optimal_feature, optimal_feature_threshold, left, right)\n",
    "    \n",
    "    def optimal_split(self, X, y, given_index):\n",
    "        \n",
    "        best = -1000000000\n",
    "        index, thresh = None, None\n",
    "        \n",
    "        for i in given_index:\n",
    "            X_column = X[:, i]\n",
    "            x_cols = np.unique(X_column)\n",
    "            \n",
    "            for i in x_cols:\n",
    "                what_to_gain = self.info(y, X_column, i)\n",
    "                if what_to_gain > best:\n",
    "                    best = what_to_gain\n",
    "                    index = i\n",
    "                    thresh = i\n",
    "        return index, thresh\n",
    "\n",
    "    def traverse(self, x, node):\n",
    "        if node.is_leaf():\n",
    "            #print(\"Leaf: \" , node.val, \". Threshold: \", node.threshold)\n",
    "            return node.val\n",
    "        if x[node.feature] < node.threshold:\n",
    "            #print(\"Node Left: \", node.feature, \". Threshold:\", node.threshold)\n",
    "            return self.traverse(x, node.left)\n",
    "        else:\n",
    "            #print(\"Node Right: \", node.feature, \". Threshold:\", node.threshold)\n",
    "            return self.traverse(x, node.right)\n",
    "\n",
    "    def split(self, X, threshold):\n",
    "        left_index = np.argwhere(X < threshold)\n",
    "        left_index = left_index.flatten()\n",
    "\n",
    "        right_index = np.argwhere(X >= threshold)\n",
    "        right_index = right_index.flatten()\n",
    "        \n",
    "        return left_index, right_index\n",
    "\n",
    "    def info(self, y, X_column, threshold):\n",
    "        before_entropy = self.entropy(y)\n",
    "\n",
    "        left, right = self.split(X_column, threshold)\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(y)\n",
    "        n_l, n_r = len(left), len(right)\n",
    "        e_l, e_r = self.entropy(y[left]), self.entropy(y[right])\n",
    "        after_entropy = (n_l / n) * e_l + (n_r / n) * e_r\n",
    "\n",
    "        return before_entropy - after_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2576adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, depth=0):\n",
    "        self.trees = []\n",
    "        self.depth = depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(10):\n",
    "            tree = DecisionTree(self.depth)\n",
    "            squeaky_boots_X, squeaky_boots_y = self.squeakyBoots(X, y)\n",
    "            \n",
    "            tree.fit(squeaky_boots_X, squeaky_boots_y)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def squeakyBoots(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        idxs = np.random.choice(n_samples, size=n_samples, replace=True)\n",
    "        return X[idxs], y[idxs]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        creepy_tree_pee = np.array([tree.predict(X) for tree in self.trees])\n",
    "        creepy_tree_pee = np.swapaxes(creepy_tree_pee, 0, 1)\n",
    "\n",
    "        most = mode(creepy_tree_pee, axis=1)[0]\n",
    "        return most.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd96c734",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = pd.read_csv('datasets/titanic/titanic_training.csv')\n",
    "\n",
    "features = ['age', 'fare', 'embarked', 'sex']\n",
    "target = 'survived'\n",
    "X = titanic_df[features]\n",
    "y = titanic_df[target].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_Imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "categorical_features = ['embarked', 'sex']\n",
    "categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[('num', numeric_Imputer, numeric_features),('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "model = DecisionTree(7) # 6: 0.801980198019802, 7:0.8217821782178217, 8:\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\n",
    "\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb00f390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "max_depths = range(1, 40)\n",
    "validation_accuracies = []\n",
    "\n",
    "X_train_np = preprocessor.transform(X_train)\n",
    "y_train_np = y_train\n",
    "X_val_np = preprocessor.transform(X_val)\n",
    "y_val_np = y_val\n",
    "\n",
    "for depth in max_depths:\n",
    "    model.fit(X_train_np, y_train_np)\n",
    "\n",
    "    y_pred = model.predict(X_val_np)\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    validation_accuracies.append(accuracy)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(max_depths, validation_accuracies)\n",
    "plt.xlabel('Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Titanic Prediction\n",
    "X_train_np = preprocessor.transform(X_train)\n",
    "y_train_np = y_train\n",
    "X_val_np = preprocessor.transform(X_val)\n",
    "y_val_np = y_val\n",
    "\n",
    "model.fit(X_train_np, y_train_np)\n",
    "\n",
    "y_pred = model.predict(X_train_np)\n",
    "print(\"Titanic Decision Tree Training Accuracy: \" , accuracy_score(y_train_np, y_pred))\n",
    "\n",
    "y_pred = model.predict(X_val_np)\n",
    "print(\"Titanic Decision Tree Validation Accuracy: \" , accuracy_score(y_val_np, y_pred))\n",
    "\n",
    "rand_forest = RandomForest(1)  #7: 0.8507992895204263,\n",
    "rand_forest.fit(X_train_np, y_train_np)\n",
    "\n",
    "y_pred = rand_forest.predict(X_train_np)\n",
    "print(\"Titanic Random Forest Traning Accuracy: \" , accuracy_score(y_train, y_pred))\n",
    "\n",
    "y_pred = rand_forest.predict(X_val_np)\n",
    "print(\"Titanic Random Forest Traning Accuracy: \" , accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abda4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, depth=1):\n",
    "    if node.is_leaf():\n",
    "        print(\"\\t\" * depth + \"Leaf: \", node.feature)\n",
    "    else:\n",
    "        print(\"\\t\" * depth + \"Node: \", node.feature,  \" = \", node.threshold)\n",
    "        if node.right is not None:\n",
    "            print(\"\\t\" * depth + \"Right: \")\n",
    "            print_tree(node.right, depth + 1)\n",
    "        if node.left is not None:\n",
    "            print(\"\\t\" * depth + \"Left: \")\n",
    "            print_tree(node.left, depth + 1)\n",
    "\n",
    "decision_tree = DecisionTree(2)\n",
    "decision_tree.fit(X_train_np, y_train_np)\n",
    "\n",
    "print_tree(decision_tree.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484cb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = sio.loadmat('datasets/spam_data/spam_data.mat')\n",
    "\n",
    "X = spam_data['training_data']\n",
    "y = spam_data['training_labels'].reshape(-1).astype(int)\n",
    "\n",
    "X_Kaggle_Test = spam_data['test_data']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "Decision_Tree = DecisionTree(6)\n",
    "Decision_Tree.fit(X, y)\n",
    "results_to_csv(Decision_Tree.predict(X_Kaggle_Test))\n",
    "guesses = Decision_Tree.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, guesses)\n",
    "print(\"Spam Data Decision tree Validation: \", accuracy) #This one\n",
    "\n",
    "guesses = Decision_Tree.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, guesses)\n",
    "print(\"Spam Data Decision tree Training: \", accuracy) #This one\n",
    "\n",
    "rand_forest = RandomForest(1)  # Adjust parameters as necessary 7: 0.8507992895204263,  \n",
    "rand_forest.fit(X, y)\n",
    "results_to_csv(rand_forest.predict(X_Kaggle_Test))\n",
    "guesses = rand_forest.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, guesses)\n",
    "print(\"Spam Data RandomForest Validation: \", accuracy)\n",
    "\n",
    "guesses = rand_forest.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, guesses)\n",
    "print(\"Spam Data RandomForest Training: \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
